{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../Project 2/CS205_SP_2022_SMALLtestdata__44.txt\", \"r\") as file:\n",
    "    data= file.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_row=[]\n",
    "for line in data:\n",
    "    row=[]\n",
    "    for col in line.split():\n",
    "        row.append(float(col))\n",
    "    dt_row.append(row)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(dt_row, columns=['target', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave out one cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= list(df.columns)\n",
    "cols1= cols[1:]\n",
    "cols1.append(cols[0])\n",
    "df= df[cols1]\n",
    "df['target']= df['target'].astype('int')\n",
    "\n",
    "#all_vals = df[list(df.columns)[:-1]].values\n",
    "#all_labels = df[list(df.columns)[-1]].values\n",
    "#all_vals.shape, all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(test_pt, train_pt):\n",
    "    dist_mat= np.round(math.sqrt(np.sum(np.abs(train_pt-test_pt)**2)), 3)\n",
    "    return dist_mat\n",
    "    \n",
    "def knn_classifier(test_data, training_data, training_labels, K=1):\n",
    "    pred_labels = np.zeros(len(test_data))\n",
    "    #print(\"pred_labels: \", pred_labels)\n",
    "\n",
    "    all_dists = np.zeros(len(training_data))\n",
    "        #print(\"all_dists: \", all_dists.shape)\n",
    "    count = 0\n",
    "    for train_pt in training_data: #for every row in train data\n",
    "        all_dists[count] = compute_dist(test_data, train_pt)\n",
    "        #print(all_dists[count])\n",
    "        count = count+1\n",
    "    \n",
    "    sorted_indices = np.argsort(all_dists)\n",
    "    pred_labels = training_labels[sorted_indices[0]]\n",
    "    #print(len(pred_labels))\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data based on Leave out one cross validation\n",
    "def loov(features_list):\n",
    "    #print(\"features_list: \", features_list)\n",
    "    \n",
    "    all_accuracy= []\n",
    "    for i in range(len(df)):\n",
    "        #if i%50==0:\n",
    "        #    print(i)\n",
    "        #train-test split\n",
    "        test_df= df.iloc[[i, ]]\n",
    "        train_df= pd.concat([df.iloc[:i, ], df.iloc[i+1: ,]])\n",
    "        X_train, X_test, y_train, y_test= train_df.iloc[:, features_list] , test_df.iloc[:, features_list], train_df.iloc[:, -1], test_df.iloc[:, -1]\n",
    "        #print(\"X_train: \", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "        #print(X_train)\n",
    "        #print(X_test)\n",
    "        pred_labels = knn_classifier(X_test.values, X_train.values, y_train.values, 1)\n",
    "        accuracy = sum(y_test.values == pred_labels)\n",
    "        #print(pred_labels, y_test.values, accuracy, len(pred_labels))\n",
    "        all_accuracy.append(accuracy)\n",
    "    return np.round(np.array(all_accuracy).mean(),3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 :: current feature list: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Best_features till now: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], Best_accuracy till now: 0.717 \n",
      "\n",
      "Iteration: 1 :: current feature list: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Worst feature:  8\n",
      "Best_features till now: [0, 1, 2, 3, 4, 5, 6, 7, 9], Best_accuracy till now: 0.747 \n",
      "\n",
      "Iteration: 2 :: current feature list: [0, 1, 2, 3, 4, 5, 6, 7, 9]\n",
      "Worst feature:  0\n",
      "Best_features till now: [1, 2, 3, 4, 5, 6, 7, 9], Best_accuracy till now: 0.78 \n",
      "\n",
      "Iteration: 3 :: current feature list: [1, 2, 3, 4, 5, 6, 7, 9]\n",
      "Worst feature:  5\n",
      "Best_features till now: [1, 2, 3, 4, 6, 7, 9], Best_accuracy till now: 0.813 \n",
      "\n",
      "Iteration: 4 :: current feature list: [1, 2, 3, 4, 6, 7, 9]\n",
      "Worst feature:  9\n",
      "Best_features till now: [1, 2, 3, 4, 6, 7], Best_accuracy till now: 0.847 \n",
      "\n",
      "Iteration: 5 :: current feature list: [1, 2, 3, 4, 6, 7]\n",
      "Worst feature:  6\n",
      "Best_features till now: [1, 2, 3, 4, 7], Best_accuracy till now: 0.873 \n",
      "\n",
      "Iteration: 6 :: current feature list: [1, 2, 3, 4, 7]\n",
      "Worst feature:  2\n",
      "Best_features till now: [1, 3, 4, 7], Best_accuracy till now: 0.907 \n",
      "\n",
      "Iteration: 7 :: current feature list: [1, 3, 4, 7]\n",
      "Worst feature:  4\n",
      "Best_features till now: [1, 3, 7], Best_accuracy till now: 0.93 \n",
      "\n",
      "Iteration: 8 :: current feature list: [1, 3, 7]\n",
      "Worst feature:  7\n",
      "Best_features till now: [1, 3], Best_accuracy till now: 0.957 \n",
      "\n",
      "Iteration: 9 :: current feature list: [1, 3]\n",
      "Worst feature:  1\n",
      "Best_features till now: [1, 3], Best_accuracy till now: 0.957 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#backward\n",
    "\n",
    "best_acc= 0\n",
    "best_features= []\n",
    "\n",
    "#converting to integer for indexing\n",
    "org_cols_list= [int(col)-1 for col in list(df.columns)[:-1]]\n",
    "feat_list=org_cols_list.copy()\n",
    "\n",
    "for itr in org_cols_list: #1->2->3->4 (how many features)\n",
    "    print(f\"Iteration: {itr} :: current feature list: {feat_list}\")\n",
    "    if itr==0:\n",
    "        best_acc= loov(org_cols_list)\n",
    "        best_features= org_cols_list.copy()\n",
    "    else:\n",
    "        features_acc=[0 for col in org_cols_list]\n",
    "        #remove one feature from feat_list\n",
    "        for idx in range(len(feat_list)): #what features\n",
    "            copy_feat_list= feat_list[:idx]+feat_list[idx+1:]#.remove(feat)\n",
    "            acc= loov(copy_feat_list) #interpret as: all exisiting features w/o feat\n",
    "            features_acc[feat_list[idx]]= acc\n",
    "    \n",
    "        #calc best accuracy: eleimate feature that had least drop in accuracy: meaning less important feature. If biggest drop in accuracy: more imp feature\n",
    "        features_acc_ind= np.argsort(features_acc)\n",
    "        #print(\"features_acc: \", features_acc)\n",
    "        print(f\"Worst feature: {features_acc_ind[-1]} with accuracy {features_acc[features_acc_ind[-1]]}\")\n",
    "        \n",
    "        feat_list.remove(features_acc_ind[-1]) #remove worst acc\n",
    "        #print(\"feat_list: \", feat_list)\n",
    "\n",
    "        if features_acc[features_acc_ind[-1]] > best_acc:\n",
    "            best_features.remove(features_acc_ind[-1])\n",
    "            best_acc= features_acc[features_acc_ind[-1]]\n",
    "        \n",
    "        \n",
    "    print(f\"Best_features till now: {best_features}, Best_accuracy till now: {best_acc} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_line_acc:  0.813\n",
      "org_feat_list:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Iteration: 0 :: current feature list: []\n",
      "Best feature:  3\n",
      "Best_features till now: [3], Best_accuracy till now: 0.827 \n",
      "\n",
      "Iteration: 1 :: current feature list: [3]\n",
      "Best feature:  1\n",
      "Best_features till now: [3, 1], Best_accuracy till now: 0.957 \n",
      "\n",
      "Iteration: 2 :: current feature list: [3, 1]\n",
      "Best feature:  8\n",
      "Best_features till now: [3, 1], Best_accuracy till now: 0.957 \n",
      "\n",
      "Iteration: 3 :: current feature list: [3, 1, 8]\n",
      "Best feature:  7\n",
      "Best_features till now: [3, 1], Best_accuracy till now: 0.957 \n",
      "\n",
      "Iteration: 4 :: current feature list: [3, 1, 8, 7]\n",
      "Best feature:  4\n",
      "Best_features till now: [3, 1], Best_accuracy till now: 0.957 \n",
      "\n",
      "Iteration: 5 :: current feature list: [3, 1, 8, 7, 4]\n",
      "Best feature:  9\n",
      "Best_features till now: [3, 1], Best_accuracy till now: 0.957 \n",
      "\n",
      "Iteration: 6 :: current feature list: [3, 1, 8, 7, 4, 9]\n",
      "Best feature:  5\n",
      "Best_features till now: [3, 1], Best_accuracy till now: 0.957 \n",
      "\n",
      "Iteration: 7 :: current feature list: [3, 1, 8, 7, 4, 9, 5]\n",
      "Best feature:  2\n",
      "Best_features till now: [3, 1], Best_accuracy till now: 0.957 \n",
      "\n",
      "Iteration: 8 :: current feature list: [3, 1, 8, 7, 4, 9, 5, 2]\n",
      "Best feature:  6\n",
      "Best_features till now: [3, 1], Best_accuracy till now: 0.957 \n",
      "\n",
      "Iteration: 9 :: current feature list: [3, 1, 8, 7, 4, 9, 5, 2, 6]\n",
      "Best feature:  0\n",
      "Best_features till now: [3, 1], Best_accuracy till now: 0.957 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "#baseline accuracy: \n",
    "freq_count= dict(df['target'].value_counts(ascending=False))\n",
    "#for every test point: assign label as the most frequent class in train data\n",
    "base_line_acc= np.round(list(freq_count.values())[0]/len(df), 3)\n",
    "print(\"base_line_acc: \", base_line_acc)\n",
    "\n",
    "#converting to integer for indexing\n",
    "org_cols_list= [int(col)-1 for col in list(df.columns)[:-1]]\n",
    "\n",
    "print(\"org_feat_list: \", org_cols_list)\n",
    "best_acc= 0\n",
    "best_features= []\n",
    "\n",
    "feat_list=[]\n",
    "\n",
    "#forward: keep best\n",
    "for itr in org_cols_list: #1->2->3->4 (how many features)\n",
    "    print(f\"Iteration: {itr} :: current feature list: {feat_list}\")\n",
    "    features_acc=[0 for col in org_cols_list]\n",
    "    for feat in org_cols_list: #what features\n",
    "        if feat not in feat_list:\n",
    "            #print(int(feat))\n",
    "            acc= loov(feat_list+[feat])\n",
    "            features_acc[feat]= acc\n",
    "    \n",
    "    #calc best accuracy\n",
    "    features_acc_ind= np.argsort(features_acc)\n",
    "    print(f\"Best feature: {features_acc_ind[-1]} with accuracy {features_acc[features_acc_ind[-1]]}\")\n",
    "    #print(\"features_acc: \", features_acc)\n",
    "\n",
    "    feat_list.append(org_cols_list[features_acc_ind[-1]])\n",
    "    #print(\"feat_list: \", feat_list)\n",
    "    if features_acc[features_acc_ind[-1]] > best_acc:\n",
    "        best_features.append(org_cols_list[features_acc_ind[-1]])\n",
    "        best_acc= features_acc[features_acc_ind[-1]]\n",
    "        \n",
    "        \n",
    "    print(f\"Best_features till now: {best_features}, Best_accuracy till now: {best_acc} \\n\")\n",
    "#backward: remove worst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('stream_lit_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12ee754ea42dfd9f99a2bb29190e432a84acb6698fa06d5386d4f247b5efae75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
